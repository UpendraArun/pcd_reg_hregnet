{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "with open(\"/workspace/results/Baseline_Hregnet/results.json\", \"r\") as file1:\n",
    "    data_dict1 = json.load(file1)\n",
    "\n",
    "with open(\"/workspace/results/Adaption1_Hregnet_mi/results.json\", \"r\") as file2:\n",
    "    data_dict2 = json.load(file2)\n",
    "\n",
    "with open(\"/workspace/results/Adaption2_ptv3/results_v1.json\", \"r\") as file3:\n",
    "    data_dict3 = json.load(file3)\n",
    "\n",
    "# with open(\"/workspace/results/Baseline_Hregnet/results.json\", \"r\") as file4:\n",
    "#     data_dict4 = json.load(file4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the top 3 best and worst samples with results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_top_worst_samples(errors, top_n=3):\n",
    "    \"\"\"\n",
    "    Given an array of shape (N,6) where columns 0:3 are rotation errors and\n",
    "    columns 3:6 are translation errors, this function computes:\n",
    "      - mean rotation error per sample (using absolute errors),\n",
    "      - mean translation error per sample (using absolute errors),\n",
    "      - a combined error (here simply the sum of the means),\n",
    "    and then returns the indices of the top_n worst samples for each error type.\n",
    "    \n",
    "    Parameters:\n",
    "      errors (np.ndarray): Array with shape (N,6).\n",
    "      top_n (int): Number of worst samples to extract.\n",
    "      \n",
    "    Returns:\n",
    "      worst_rot_indices (np.ndarray): Indices of samples with largest mean rotation error.\n",
    "      worst_trans_indices (np.ndarray): Indices of samples with largest mean translation error.\n",
    "      worst_combined_indices (np.ndarray): Indices of samples with largest combined error.\n",
    "      mean_rot (np.ndarray): Mean rotation error per sample.\n",
    "      mean_trans (np.ndarray): Mean translation error per sample.\n",
    "      combined_error (np.ndarray): Combined error per sample.\n",
    "    \"\"\"\n",
    "    # Compute the mean absolute error for rotation (first 3 columns) and translation (last 3 columns)\n",
    "    mean_rot = np.mean(np.abs(errors[:, :3]), axis=1)\n",
    "    mean_trans = np.mean(np.abs(errors[:, 3:]), axis=1)\n",
    "    \n",
    "    # Combined error: here we simply add them, but you could use a weighted sum if desired.\n",
    "    combined_error = mean_rot + mean_trans\n",
    "\n",
    "    # Get indices that would sort the array in descending order\n",
    "    worst_rot_indices = np.argsort(mean_rot)[::-1][:top_n]\n",
    "    worst_trans_indices = np.argsort(mean_trans)[::-1][:top_n]\n",
    "    worst_combined_indices = np.argsort(combined_error)[::-1][:top_n]\n",
    "    \n",
    "    return worst_rot_indices, worst_trans_indices, worst_combined_indices, mean_rot, mean_trans, combined_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each\n",
    "    errors = np.asarray(data_dict1['layer_2']['error_calib'])  # Using randn for demonstration, including negative values\n",
    "    top_n = 10  # Change this value for top-n worst samples\n",
    "    \n",
    "    worst_rot_idx, worst_trans_idx, worst_combined_idx, mean_rot, mean_trans, combined_error = \\\n",
    "                                                    find_top_worst_samples(errors, top_n)\n",
    "    \n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in worst_rot_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in worst_trans_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for combined error:\")\n",
    "    for idx in worst_combined_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}, Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "        print(f\"  Combined Error: {combined_error[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each\n",
    "    errors = np.asarray(data_dict2['layer_2']['error_calib'])  # Using randn for demonstration, including negative values\n",
    "    top_n = 10  # Change this value for top-n worst samples\n",
    "    \n",
    "    worst_rot_idx, worst_trans_idx, worst_combined_idx, mean_rot, mean_trans, combined_error = \\\n",
    "                                                    find_top_worst_samples(errors, top_n)\n",
    "    \n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in worst_rot_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in worst_trans_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for combined error:\")\n",
    "    for idx in worst_combined_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}, Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "        print(f\"  Combined Error: {combined_error[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each\n",
    "    errors = np.asarray(data_dict3['layer_2']['error_calib'])  # Using randn for demonstration, including negative values\n",
    "    top_n = 10  # Change this value for top-n worst samples\n",
    "    \n",
    "    worst_rot_idx, worst_trans_idx, worst_combined_idx, mean_rot, mean_trans, combined_error = \\\n",
    "                                                    find_top_worst_samples(errors, top_n)\n",
    "    \n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in worst_rot_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in worst_trans_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop worst samples for combined error:\")\n",
    "    for idx in worst_combined_idx:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {mean_rot[idx]:.4f}, Mean Translation Error: {mean_trans[idx]:.4f}\")\n",
    "        print(f\"  Combined Error: {combined_error[idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_top_worst_and_best_samples(errors, top_n=3):\n",
    "    \"\"\"\n",
    "    Given an array of shape (N,6) where:\n",
    "      - Columns 0:3 are rotation errors,\n",
    "      - Columns 3:6 are translation errors,\n",
    "    this function computes:\n",
    "      - Mean absolute rotation error per sample,\n",
    "      - Mean absolute translation error per sample,\n",
    "      - Combined error (sum of the two means).\n",
    "    \n",
    "    It returns the indices for the top_n worst (largest error) and \n",
    "    top_n best (lowest error) samples for each error type, along with the\n",
    "    computed error metrics.\n",
    "    \n",
    "    Parameters:\n",
    "      errors (np.ndarray): Array with shape (N,6).\n",
    "      top_n (int): Number of samples to extract for worst and best.\n",
    "      \n",
    "    Returns:\n",
    "      A dictionary with the following keys:\n",
    "        'worst_rot_indices', 'worst_trans_indices', 'worst_combined_indices',\n",
    "        'best_rot_indices', 'best_trans_indices', 'best_combined_indices',\n",
    "        'mean_rot', 'mean_trans', 'combined_error'.\n",
    "    \"\"\"\n",
    "    # Compute mean absolute errors\n",
    "    mean_rot = np.mean(np.abs(errors[:, :3]), axis=1)\n",
    "    mean_trans = np.mean(np.abs(errors[:, 3:]), axis=1)\n",
    "    combined_error = mean_rot + mean_trans\n",
    "\n",
    "    # Worst (highest errors): sort in descending order.\n",
    "    worst_rot_indices = np.argsort(mean_rot)[::-1][:top_n]\n",
    "    worst_trans_indices = np.argsort(mean_trans)[::-1][:top_n]\n",
    "    worst_combined_indices = np.argsort(combined_error)[::-1][:top_n]\n",
    "\n",
    "    # Best (lowest errors): sort in ascending order.\n",
    "    best_rot_indices = np.argsort(mean_rot)[:top_n]\n",
    "    best_trans_indices = np.argsort(mean_trans)[:top_n]\n",
    "    best_combined_indices = np.argsort(combined_error)[:top_n]\n",
    "\n",
    "    return {\n",
    "        'worst_rot_indices': worst_rot_indices,\n",
    "        'worst_trans_indices': worst_trans_indices,\n",
    "        'worst_combined_indices': worst_combined_indices,\n",
    "        'best_rot_indices': best_rot_indices,\n",
    "        'best_trans_indices': best_trans_indices,\n",
    "        'best_combined_indices': best_combined_indices,\n",
    "        'mean_rot': mean_rot,\n",
    "        'mean_trans': mean_trans,\n",
    "        'combined_error': combined_error\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top worst samples for rotation error:\n",
      "Sample 4441:\n",
      "  Error vector: [-2.57389426e-01  2.99025681e-02  9.25988579e+00 -3.17627579e-01\n",
      "  3.23074311e-03 -1.48987919e-02]\n",
      "  Mean Rotation Error: 3.1824\n",
      "Sample 4449:\n",
      "  Error vector: [-0.1904029  -0.27965638  4.79625273  0.02336299  0.2260092  -0.04500031]\n",
      "  Mean Rotation Error: 1.7554\n",
      "Sample 4453:\n",
      "  Error vector: [ 0.09553131  0.03686029 -5.07584715 -0.52186835 -0.18811673  0.06064975]\n",
      "  Mean Rotation Error: 1.7361\n",
      "Sample 4447:\n",
      "  Error vector: [-0.0414665  -0.25992972  3.75358868 -0.08797139  0.17741162 -0.03754771]\n",
      "  Mean Rotation Error: 1.3517\n",
      "Sample 649:\n",
      "  Error vector: [ 0.50703168 -0.11329841 -3.13870215  0.12488253 -0.03298919  0.12392209]\n",
      "  Mean Rotation Error: 1.2530\n",
      "Sample 435:\n",
      "  Error vector: [ 0.05668886  0.2206654  -3.31938958 -0.26748946 -0.16732745  0.03127741]\n",
      "  Mean Rotation Error: 1.1989\n",
      "Sample 1109:\n",
      "  Error vector: [-0.74521077  1.00152409 -1.63653493  0.14996135  0.05086672 -0.04908585]\n",
      "  Mean Rotation Error: 1.1278\n",
      "Sample 3531:\n",
      "  Error vector: [ 0.16797771 -0.18907706 -2.81735611  0.65566194  1.1985997  -0.00470014]\n",
      "  Mean Rotation Error: 1.0581\n",
      "Sample 3527:\n",
      "  Error vector: [-0.01063376 -0.02750091 -2.57393646  0.17414324  0.07788733  0.01206817]\n",
      "  Mean Rotation Error: 0.8707\n",
      "Sample 1486:\n",
      "  Error vector: [-8.53637084e-02 -5.30543551e-02  2.42605495e+00 -1.26044661e-01\n",
      " -1.77377313e-01 -2.29994208e-03]\n",
      "  Mean Rotation Error: 0.8548\n",
      "\n",
      "Top worst samples for translation error:\n",
      "Sample 1576:\n",
      "  Error vector: [ 0.04073133  0.22982368  0.25511134 -2.21657538  1.20108807 -0.15882856]\n",
      "  Mean Translation Error: 1.1922\n",
      "Sample 4732:\n",
      "  Error vector: [ 0.6792348  -0.54858613 -0.88409632  1.17592633  1.08236778  0.04527711]\n",
      "  Mean Translation Error: 0.7679\n",
      "Sample 3531:\n",
      "  Error vector: [ 0.16797771 -0.18907706 -2.81735611  0.65566194  1.1985997  -0.00470014]\n",
      "  Mean Translation Error: 0.6197\n",
      "Sample 4445:\n",
      "  Error vector: [-0.111474   -0.07777283 -1.62542832 -0.70435339 -0.38829422  0.01858166]\n",
      "  Mean Translation Error: 0.3704\n",
      "Sample 3537:\n",
      "  Error vector: [ 0.02928531 -0.03015955 -0.54234958 -0.21097524  0.83991438 -0.02444604]\n",
      "  Mean Translation Error: 0.3584\n",
      "Sample 3525:\n",
      "  Error vector: [ 0.11679133 -0.05698406  0.00497271 -0.0377017   0.92442364  0.00402004]\n",
      "  Mean Translation Error: 0.3220\n",
      "Sample 1500:\n",
      "  Error vector: [-0.09767054 -0.07619847  0.90659106 -0.68491268 -0.13852371  0.02436554]\n",
      "  Mean Translation Error: 0.2826\n",
      "Sample 5620:\n",
      "  Error vector: [-0.35096169  0.44249138 -0.24024767 -0.23277946  0.47521427  0.08447313]\n",
      "  Mean Translation Error: 0.2642\n",
      "Sample 4453:\n",
      "  Error vector: [ 0.09553131  0.03686029 -5.07584715 -0.52186835 -0.18811673  0.06064975]\n",
      "  Mean Translation Error: 0.2569\n",
      "Sample 4762:\n",
      "  Error vector: [-0.03785601 -0.08965625 -0.41947672  0.33065793  0.36642614 -0.06781089]\n",
      "  Mean Translation Error: 0.2550\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each.\n",
    "    # Here we use np.random.randn to simulate errors (can include negatives).\n",
    "    errors = np.asarray(data_dict1[\"layer_2\"][\"error_calib\"])\n",
    "    top_n = 10  # You can change this value for top-n samples\n",
    "    \n",
    "    results = find_top_worst_and_best_samples(errors, top_n)\n",
    "    \n",
    "   # Print worst cases for rotation error\n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in results['worst_rot_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for rotation error\n",
    "    # print(\"\\nTop best samples for rotation error:\")\n",
    "    # for idx in results['best_rot_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    # Print worst cases for translation error\n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in results['worst_trans_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for translation error\n",
    "    # print(\"\\nTop best samples for translation error:\")\n",
    "    # for idx in results['best_trans_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print worst cases for combined error\n",
    "    # print(\"\\nTop worst samples for combined error:\")\n",
    "    # for idx in results['worst_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for combined error\n",
    "    # print(\"\\nTop best samples for combined error:\")\n",
    "    # for idx in results['best_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top worst samples for rotation error:\n",
      "Sample 3522:\n",
      "  Error vector: [-0.94711095 -0.60754728 18.31342697  0.5962981   0.77591121 -0.17417666]\n",
      "  Mean Rotation Error: 6.6227\n",
      "Sample 4243:\n",
      "  Error vector: [-0.31940502 -0.17232572 16.26076698 -0.15190145  0.20084229 -0.03207793]\n",
      "  Mean Rotation Error: 5.5842\n",
      "Sample 3527:\n",
      "  Error vector: [ 0.11209772 -0.43064579 -8.83057022 -0.0349829   0.16458568 -0.05302125]\n",
      "  Mean Rotation Error: 3.1244\n",
      "Sample 4453:\n",
      "  Error vector: [ 1.45927280e-01 -5.41443713e-02 -8.96871090e+00  1.22793868e-01\n",
      " -3.90929356e-03  3.72350439e-02]\n",
      "  Mean Rotation Error: 3.0563\n",
      "Sample 1640:\n",
      "  Error vector: [ 0.02655949 -0.27795735 -7.6625452   0.27239567  0.35535023 -0.01330807]\n",
      "  Mean Rotation Error: 2.6557\n",
      "Sample 4447:\n",
      "  Error vector: [-0.13006184 -0.14537306  6.58411264 -0.20428599  0.18819955 -0.02788025]\n",
      "  Mean Rotation Error: 2.2865\n",
      "Sample 1510:\n",
      "  Error vector: [-6.52050823e-02 -1.62054986e-01 -5.49583149e+00 -7.24892989e-02\n",
      "  1.49932608e-01 -2.12944113e-03]\n",
      "  Mean Rotation Error: 1.9077\n",
      "Sample 1516:\n",
      "  Error vector: [ 7.02838739e-03 -3.47022712e-01 -4.79560423e+00 -3.46996151e-02\n",
      "  6.38516024e-02  1.32724643e-04]\n",
      "  Mean Rotation Error: 1.7166\n",
      "Sample 2709:\n",
      "  Error vector: [ 0.00651025  0.14121944  4.91531944 -0.10147731 -0.04200879  0.06175365]\n",
      "  Mean Rotation Error: 1.6877\n",
      "Sample 3747:\n",
      "  Error vector: [-0.239061   -0.25072935 -4.01179266 -0.03414679  0.27737516  0.01915386]\n",
      "  Mean Rotation Error: 1.5005\n",
      "\n",
      "Top worst samples for translation error:\n",
      "Sample 1480:\n",
      "  Error vector: [ 0.14007202  0.06376581  1.25298107 -1.28669333 -1.80865729  0.0199977 ]\n",
      "  Mean Translation Error: 1.0384\n",
      "Sample 3522:\n",
      "  Error vector: [-0.94711095 -0.60754728 18.31342697  0.5962981   0.77591121 -0.17417666]\n",
      "  Mean Translation Error: 0.5155\n",
      "Sample 1576:\n",
      "  Error vector: [-0.07466117  0.3090556   1.08940005 -0.77472365 -0.05937698 -0.1026834 ]\n",
      "  Mean Translation Error: 0.3123\n",
      "Sample 138:\n",
      "  Error vector: [ 0.02034452  0.23807313 -0.05711186  0.38709059 -0.23264173  0.06491764]\n",
      "  Mean Translation Error: 0.2282\n",
      "Sample 3530:\n",
      "  Error vector: [-0.08614729 -0.03765772 -0.16527942  0.24902406  0.39789176  0.01038056]\n",
      "  Mean Translation Error: 0.2191\n",
      "Sample 5634:\n",
      "  Error vector: [-0.2242786   0.30920181 -0.16683964 -0.36508286  0.24073297  0.04619712]\n",
      "  Mean Translation Error: 0.2173\n",
      "Sample 1640:\n",
      "  Error vector: [ 0.02655949 -0.27795735 -7.6625452   0.27239567  0.35535023 -0.01330807]\n",
      "  Mean Translation Error: 0.2137\n",
      "Sample 3519:\n",
      "  Error vector: [-0.39075083  0.34993926 -0.37387407  0.25784901 -0.3504771   0.02282694]\n",
      "  Mean Translation Error: 0.2104\n",
      "Sample 962:\n",
      "  Error vector: [-0.05938165  0.02333619 -0.04678256 -0.31066054  0.24891871  0.05519021]\n",
      "  Mean Translation Error: 0.2049\n",
      "Sample 1237:\n",
      "  Error vector: [-0.06819903 -0.14738129 -0.41031873 -0.26504451  0.27102953 -0.07820538]\n",
      "  Mean Translation Error: 0.2048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each.\n",
    "    # Here we use np.random.randn to simulate errors (can include negatives).\n",
    "    errors = np.asarray(data_dict2[\"layer_2\"][\"error_calib\"])\n",
    "    top_n = 10  # You can change this value for top-n samples\n",
    "    \n",
    "    results = find_top_worst_and_best_samples(errors, top_n)\n",
    "    \n",
    "   # Print worst cases for rotation error\n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in results['worst_rot_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for rotation error\n",
    "    # print(\"\\nTop best samples for rotation error:\")\n",
    "    # for idx in results['best_rot_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    # Print worst cases for translation error\n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in results['worst_trans_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for translation error\n",
    "    # print(\"\\nTop best samples for translation error:\")\n",
    "    # for idx in results['best_trans_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print worst cases for combined error\n",
    "    # print(\"\\nTop worst samples for combined error:\")\n",
    "    # for idx in results['worst_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for combined error\n",
    "    # print(\"\\nTop best samples for combined error:\")\n",
    "    # for idx in results['best_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top worst samples for rotation error:\n",
      "Sample 1185:\n",
      "  Error vector: [-0.72823817  0.31101248 -4.9603982   0.16866079 -0.0146072  -0.03818147]\n",
      "  Mean Rotation Error: 1.9999\n",
      "Sample 1849:\n",
      "  Error vector: [-0.10580648  0.44594416 -4.26436949 -0.063434   -0.55832404  0.04151502]\n",
      "  Mean Rotation Error: 1.6054\n",
      "Sample 2198:\n",
      "  Error vector: [0.46597937 0.19018996 3.4626503  0.04122585 0.092994   0.02502996]\n",
      "  Mean Rotation Error: 1.3729\n",
      "Sample 1502:\n",
      "  Error vector: [ 0.14186481  0.03627215 -3.19671607 -0.07927838  0.04865062  0.04648799]\n",
      "  Mean Rotation Error: 1.1250\n",
      "Sample 1513:\n",
      "  Error vector: [ 0.02935445 -0.06307681 -3.04806447 -0.12738025 -0.12071222  0.01032528]\n",
      "  Mean Rotation Error: 1.0468\n",
      "Sample 1500:\n",
      "  Error vector: [-0.14670616  0.01614187 -2.96092844 -0.11135851 -0.08357945  0.0089801 ]\n",
      "  Mean Rotation Error: 1.0413\n",
      "Sample 439:\n",
      "  Error vector: [ 0.28027865  0.17195198 -2.61997557 -0.24815594  0.04888733  0.03801357]\n",
      "  Mean Rotation Error: 1.0241\n",
      "Sample 1843:\n",
      "  Error vector: [-0.01233618  0.12301522 -2.74479246  0.22759829 -0.19024312 -0.0125784 ]\n",
      "  Mean Rotation Error: 0.9600\n",
      "Sample 4445:\n",
      "  Error vector: [ 0.21026038  0.18605895 -2.20513415 -0.01391119 -0.07462545  0.09975654]\n",
      "  Mean Rotation Error: 0.8672\n",
      "Sample 1691:\n",
      "  Error vector: [ 0.43871835 -0.32405749 -1.44034445 -0.07884018  0.13353616 -0.03012567]\n",
      "  Mean Rotation Error: 0.7344\n",
      "\n",
      "Top worst samples for translation error:\n",
      "Sample 1576:\n",
      "  Error vector: [-0.35289481 -0.09418152  0.50045371 -1.10107231  0.0415691  -0.25149173]\n",
      "  Mean Translation Error: 0.4647\n",
      "Sample 3522:\n",
      "  Error vector: [ 0.02358553 -0.01024358 -1.60047209  0.39237279  0.56758249 -0.00740197]\n",
      "  Mean Translation Error: 0.3225\n",
      "Sample 2982:\n",
      "  Error vector: [ 0.08599313 -0.10193892  0.11637209 -0.37454993  0.30836073 -0.01693171]\n",
      "  Mean Translation Error: 0.2333\n",
      "Sample 1849:\n",
      "  Error vector: [-0.10580648  0.44594416 -4.26436949 -0.063434   -0.55832404  0.04151502]\n",
      "  Mean Translation Error: 0.2211\n",
      "Sample 5634:\n",
      "  Error vector: [-0.09805596 -0.07159385  0.02339263 -0.36052179  0.25413018 -0.02813232]\n",
      "  Mean Translation Error: 0.2143\n",
      "Sample 4063:\n",
      "  Error vector: [-0.14918533 -0.11253598  0.05638649 -0.31047302  0.27569866 -0.0416271 ]\n",
      "  Mean Translation Error: 0.2093\n",
      "Sample 618:\n",
      "  Error vector: [-0.04944033  0.04019652 -0.14717917 -0.33781177  0.26178968 -0.02010403]\n",
      "  Mean Translation Error: 0.2066\n",
      "Sample 1791:\n",
      "  Error vector: [-0.07600473 -0.08888385 -0.02819784 -0.2757943   0.25997487 -0.07102934]\n",
      "  Mean Translation Error: 0.2023\n",
      "Sample 1432:\n",
      "  Error vector: [-0.14102848  0.00511112  0.40260345 -0.36001709  0.19866034 -0.02745536]\n",
      "  Mean Translation Error: 0.1954\n",
      "Sample 5180:\n",
      "  Error vector: [-0.06536622 -0.04923543 -0.26529306 -0.27234849  0.26145673 -0.05014065]\n",
      "  Mean Translation Error: 0.1946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    # For reproducibility\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # Suppose we have 100 samples with 6 error values each.\n",
    "    # Here we use np.random.randn to simulate errors (can include negatives).\n",
    "    errors = np.asarray(data_dict3[\"layer_2\"][\"error_calib\"])\n",
    "    top_n = 10  # You can change this value for top-n samples\n",
    "    \n",
    "    results = find_top_worst_and_best_samples(errors, top_n)\n",
    "    \n",
    "    #Print worst cases for rotation error\n",
    "    print(\"Top worst samples for rotation error:\")\n",
    "    for idx in results['worst_rot_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    #Print best cases for rotation error\n",
    "    # print(\"\\nTop best samples for rotation error:\")\n",
    "    # for idx in results['best_rot_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}\")\n",
    "    \n",
    "    #Print worst cases for translation error\n",
    "    print(\"\\nTop worst samples for translation error:\")\n",
    "    for idx in results['worst_trans_indices']:\n",
    "        print(f\"Sample {idx}:\")\n",
    "        print(f\"  Error vector: {errors[idx]}\")\n",
    "        print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for translation error\n",
    "    # print(\"\\nTop best samples for translation error:\")\n",
    "    # for idx in results['best_trans_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    \n",
    "    # Print worst cases for combined error\n",
    "    # print(\"\\nTop worst samples for combined error:\")\n",
    "    # for idx in results['worst_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")\n",
    "    \n",
    "    # Print best cases for combined error\n",
    "    # print(\"\\nTop best samples for combined error:\")\n",
    "    # for idx in results['best_combined_indices']:\n",
    "    #     print(f\"Sample {idx}:\")\n",
    "    #     print(f\"  Error vector: {errors[idx]}\")\n",
    "    #     print(f\"  Mean Rotation Error: {results['mean_rot'][idx]:.4f}, Mean Translation Error: {results['mean_trans'][idx]:.4f}\")\n",
    "    #     print(f\"  Combined Error: {results['combined_error'][idx]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
